{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Introdução\n","\n","Dado o cenário de ano eleitoral no Brasil, este trabalho procura entender de maneira simplificada o contexto atual das eleições. Utilizaremos dados obtidos no Twitter, rede social em que os candidatos e candidatas geralmente propagam mensagens com suas ideias e propostas. Lá também é possível encontrar a manifestação dos sentimentos dos eleitores através de suas opiniões sobre os candidatos, sejam elas contra ou a favor.\n","\n","Os dados foram coletados diretamente da API do Twitter, e inclui 100 tweets recentes de cada um dos três principais candidatos - de acordo com as pesquisas eleitorais -, assim como diversas respostas (replies) para cada um dos tweets de cada candidato.\n","\n","Procuramos responder alguns questionamentos:\n","- Quais os principais tópicos que estão sendo abordados pelos candidatos?\n","- Quão similar é o discurso entre os candidatos?\n","- Qual o sentimento dos eleitores sobre cada candidato?\n","\n","Com as repostas a estas perguntas, acreditamos que seja possível visualizar um pouco melhor o cenário das eleições para presidência do Brasil, que em breve serão iniciadas.\n","\n","Além disso, é importante mencionar que os resultados apresentados por este notebook podem variar entre diferentes execuções. Do mesmo modo, os exemplos apresentados no vídeo do projeto podem ser distintos dos que aparecem neste notebook e em suas futuras execuções."]},{"cell_type":"markdown","metadata":{"id":"dplAA4R5mRrE"},"source":["##Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1660869356185,"user":{"displayName":"Juliana Thomaz","userId":"10883141159324758422"},"user_tz":180},"id":"OWFK6d3QmRKE"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /home/lucas/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /home/lucas/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import re\n","import pandas as pd\n","import json\n","import nltk\n","import numpy as np\n","\n","#Imports similaridade\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","nltk.download('stopwords')\n","nltk.download('punkt')"]},{"cell_type":"markdown","metadata":{"id":"muyhJsQRVfZH"},"source":["# Extração de Dados"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def df_tweets_candidatos(json_filename):\n","    df = pd.read_json(json_filename).drop(columns = ['replies'])\n","    return df\n","\n","\n","def df_tweets_respostas(json_filename):\n","    df = pd.read_json(json_filename).dropna().reset_index()[['replies']]\n","    ds = []\n","    for replies in df['replies'].to_list():\n","        for reply in replies:\n","            ds.append(reply)\n","\n","    reply_df = pd.DataFrame (ds).drop(columns = ['attachments'])\n","    return reply_df\n","\n","def df_tweets_cadidatos_respostas(json_filename):\n","    df_tweets_cand = df_tweets_candidatos(json_filename)\n","    df_tweets_reps = df_tweets_respostas(json_filename)\n","\n","    return (df_tweets_cand, df_tweets_reps)"]},{"cell_type":"markdown","metadata":{"id":"apymyF3WWswV"},"source":["# Pré-Processamento"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"3dHR9A7RWwZU"},"outputs":[],"source":["def normaliza(df, coluna_alvo='text'):\n","  coluna_normal = coluna_alvo+\"_normal\"\n","  df[coluna_normal] = df[coluna_alvo].str.lower()\n","  df[coluna_normal].replace(to_replace = '[^a-zA-ZÀ-ÖØ-öø-ÿ\\s]', value='', regex = True, inplace = True)\n","  return df\n","  \n","def tokeniza(df, coluna_alvo='text_normal'):\n","  stop_words = nltk.corpus.stopwords.words('portuguese')\n","  todos_tokens = []\n","  todos_textos_tokens = []\n","\n","  for texto_normal in df[coluna_alvo].to_list():\n","    tokens = nltk.word_tokenize(texto_normal, language=\"portuguese\")\n","    tokens_filtrados = [token for token in tokens if token not in stop_words]\n","    todos_tokens.append(tokens_filtrados)\n","    texto_tokens = ' '.join(tokens_filtrados)\n","    todos_textos_tokens.append(texto_tokens)\n","\n","\n","  df_tokens = pd.DataFrame({'tokens': todos_tokens, 'texto_tokens': todos_textos_tokens})\n","  df_concat = pd.concat([df, df_tokens], axis=\"columns\")\n","\n","  return df_concat\n","\n","\n","def normaliza_tokeniza(df, coluna_alvo = 'text'):\n","  df_tokens = tokeniza(normaliza(df, coluna_alvo), coluna_alvo)\n","  return df_tokens\n","\n","  #word_regex = r\"[-'a-zA-ZÀ-ÖØ-öø-ÿ]+\" #para capturarmos palavras dentro do tweet\n","  #df['text'] = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', df['text'], flags=re.MULTILINE)  #para remover os links do campo de texto do tweet"]},{"cell_type":"markdown","metadata":{"id":"ZV-mwXjWVoLT"},"source":["# Modelagem de Tópicos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VJBsIdssWQC3"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"HooJDbp4WERL"},"source":["*texto em itálico*# Análise de Sentimentos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ANENPKpmWQeE"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"wYl-0IqqWI6u"},"source":["# Similaridade de Textos"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"5LANdfj4WRBM"},"outputs":[],"source":["def monta_docs_tweets(df, coluna_alvo, candidatos):\n","    lista_tweets = []\n","    for cand in candidatos:\n","        df_cand = df[df['candidato'] == cand]\n","        lista_tweets_cand = df_cand[coluna_alvo].to_list()\n","        lista_tweets.append(lista_tweets_cand)\n","    \n","    docs = np.concatenate(lista_tweets)\n","    return docs\n","\n","def monta_docs_concat(df, topico, coluna_alvo, candidatos):\n","    docs = []\n","    for cand in candidatos:\n","        df_filtrado = df[df['topico'] == topico and df['candidato'] == cand]\n","        texto = ' '.join(df_filtrado[coluna_alvo].to_list())\n","        docs.append(texto)\n"," \n","    return docs\n","\n","def vetoriza_docs(lista_docs):\n","    corpus_vetorizado = np.vectorize(lista_docs)\n","    return corpus_vetorizado\n","\n","def gera_matriz_tfidf(corpus_vetorizado):\n","    tf = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n","    matriz_tfidf = tf.fit_transform(corpus_vetorizado)\n","    return matriz_tfidf\n","\n","def similaridade_pares(matriz_tfidf):\n","    dict_docs_sim = cosine_similarity(matriz_tfidf)\n","    df_sim = pd.DataFrame(dict_docs_sim)\n","    return df_sim\n","\n","def calcula_similaridade(df, topico, coluna_alvo, candidatos):\n","    lista_docs = monta_docs_concat(df, topico, coluna_alvo, candidatos)\n","    corpus_vetorizado = vetoriza_docs(lista_docs)\n","    matriz_tfidf = gera_matriz_tfidf(corpus_vetorizado)\n","    df_sim = similaridade_pares(matriz_tfidf)\n","\n","    return df_sim"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Projeto2-PLN.ipynb","provenance":[]},"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"},"kernelspec":{"display_name":"Python 3.9.5 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}
