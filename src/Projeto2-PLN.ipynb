{"cells":[{"cell_type":"markdown","metadata":{"id":"dplAA4R5mRrE"},"source":["##Imports"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1660869356185,"user":{"displayName":"Juliana Thomaz","userId":"10883141159324758422"},"user_tz":180},"id":"OWFK6d3QmRKE"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /home/lucas/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /home/lucas/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["import re\n","import pandas as pd\n","import json\n","import nltk\n","import numpy as np\n","\n","#Imports similaridade\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","nltk.download('stopwords')\n","nltk.download('punkt')"]},{"cell_type":"markdown","metadata":{"id":"muyhJsQRVfZH"},"source":["# Extração de Dados"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def df_tweets_candidatos(json_filename):\n","    df = pd.read_json(json_filename).drop(columns = ['replies'])\n","    return df\n","\n","\n","def df_tweets_respostas(json_filename):\n","    df = pd.read_json(json_filename).dropna().reset_index()[['replies']]\n","    ds = []\n","    for replies in df['replies'].to_list():\n","        for reply in replies:\n","            ds.append(reply)\n","\n","    reply_df = pd.DataFrame (ds).drop(columns = ['attachments'])\n","    return reply_df\n","\n","def df_tweets_cadidatos_respostas(json_filename):\n","    df_tweets_cand = df_tweets_candidatos(json_filename)\n","    df_tweets_reps = df_tweets_respostas(json_filename)\n","\n","    return (df_tweets_cand, df_tweets_reps)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>created_at</th>\n","      <th>author_id</th>\n","      <th>id</th>\n","      <th>conversation_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Todo mundo viu esse papo de altíssimo nível co...</td>\n","      <td>2022-08-19 01:31:22+00:00</td>\n","      <td>33374761</td>\n","      <td>1560439246913257472</td>\n","      <td>1560439246913257472</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>É isso que a gente necessita: desarmar. Precis...</td>\n","      <td>2022-08-18 22:41:15+00:00</td>\n","      <td>33374761</td>\n","      <td>1560396436294062080</td>\n","      <td>1560396434725376000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Pare pra pensar e me responda: se Bolsonaro ou...</td>\n","      <td>2022-08-18 22:41:15+00:00</td>\n","      <td>33374761</td>\n","      <td>1560396434725376000</td>\n","      <td>1560396434725376000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Ninguém tem direito de explorar o jeito do pov...</td>\n","      <td>2022-08-18 22:38:57+00:00</td>\n","      <td>33374761</td>\n","      <td>1560395854887936000</td>\n","      <td>1560395854887936000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Dizer que eu não votei em 2018 é picaretagem a...</td>\n","      <td>2022-08-18 22:01:32+00:00</td>\n","      <td>33374761</td>\n","      <td>1560386438398898176</td>\n","      <td>1560386438398898176</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  \\\n","0  Todo mundo viu esse papo de altíssimo nível co...   \n","1  É isso que a gente necessita: desarmar. Precis...   \n","2  Pare pra pensar e me responda: se Bolsonaro ou...   \n","3  Ninguém tem direito de explorar o jeito do pov...   \n","4  Dizer que eu não votei em 2018 é picaretagem a...   \n","\n","                 created_at  author_id                   id  \\\n","0 2022-08-19 01:31:22+00:00   33374761  1560439246913257472   \n","1 2022-08-18 22:41:15+00:00   33374761  1560396436294062080   \n","2 2022-08-18 22:41:15+00:00   33374761  1560396434725376000   \n","3 2022-08-18 22:38:57+00:00   33374761  1560395854887936000   \n","4 2022-08-18 22:01:32+00:00   33374761  1560386438398898176   \n","\n","       conversation_id  \n","0  1560439246913257472  \n","1  1560396434725376000  \n","2  1560396434725376000  \n","3  1560395854887936000  \n","4  1560386438398898176  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["df2 = df_tweets_cadidatos_respostas('datasets/ciro-result.json')\n","df2[0].head()"]},{"cell_type":"markdown","metadata":{"id":"apymyF3WWswV"},"source":["# Pré-Processamento"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"3dHR9A7RWwZU"},"outputs":[],"source":["def normaliza(df, coluna_alvo='text'):\n","  coluna_normal = coluna_alvo+\"_normal\"\n","  df[coluna_normal] = df[coluna_alvo].str.lower()\n","  df[coluna_normal].replace(to_replace = '[^a-zA-ZÀ-ÖØ-öø-ÿ\\s]', value='', regex = True, inplace = True)\n","  return df\n","  \n","def tokeniza(df, coluna_alvo='text_normal'):\n","  stop_words = nltk.corpus.stopwords.words('portuguese')\n","  todos_tokens = []\n","  todos_textos_tokens = []\n","  ind = 0\n","\n","  for texto_normal in df[coluna_alvo].to_list():\n","    tokens = nltk.word_tokenize(texto_normal, language=\"portuguese\")\n","    tokens_filtrados = [token for token in tokens if token not in stop_words]\n","    todos_tokens.append(tokens_filtrados)\n","    texto_tokens = ' '.join(tokens_filtrados)\n","    todos_textos_tokens.append(texto_tokens)\n","    ind += 1\n","\n","  df_tokens = pd.DataFrame({'tokens': todos_tokens, 'texto_tokens': todos_textos_tokens})\n","  df_concat = pd.concat([df, df_tokens], axis=\"columns\")\n","\n","  return df_concat\n","\n","\n","def normaliza_tokeniza(df, coluna_alvo = 'text'):\n","  df_tokens = tokeniza(normaliza(df, coluna_alvo), coluna_alvo)\n","  return df_tokens\n","\n","  #word_regex = r\"[-'a-zA-ZÀ-ÖØ-öø-ÿ]+\" #para capturarmos palavras dentro do tweet\n","  #df['text'] = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', df['text'], flags=re.MULTILINE)  #para remover os links do campo de texto do tweet"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>created_at</th>\n","      <th>author_id</th>\n","      <th>id</th>\n","      <th>conversation_id</th>\n","      <th>text_normal</th>\n","      <th>tokens</th>\n","      <th>texto_tokens</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Todo mundo viu esse papo de altíssimo nível co...</td>\n","      <td>2022-08-19 01:31:22+00:00</td>\n","      <td>33374761</td>\n","      <td>1560439246913257472</td>\n","      <td>1560439246913257472</td>\n","      <td>todo mundo viu esse papo de altíssimo nível co...</td>\n","      <td>[Todo, mundo, viu, papo, altíssimo, nível, que...</td>\n","      <td>Todo mundo viu papo altíssimo nível querido @ ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>É isso que a gente necessita: desarmar. Precis...</td>\n","      <td>2022-08-18 22:41:15+00:00</td>\n","      <td>33374761</td>\n","      <td>1560396436294062080</td>\n","      <td>1560396434725376000</td>\n","      <td>é isso que a gente necessita desarmar precisam...</td>\n","      <td>[É, gente, necessita, :, desarmar, ., Precisam...</td>\n","      <td>É gente necessita : desarmar . Precisamos reco...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Pare pra pensar e me responda: se Bolsonaro ou...</td>\n","      <td>2022-08-18 22:41:15+00:00</td>\n","      <td>33374761</td>\n","      <td>1560396434725376000</td>\n","      <td>1560396434725376000</td>\n","      <td>pare pra pensar e me responda se bolsonaro ou ...</td>\n","      <td>[Pare, pra, pensar, responda, :, Bolsonaro, Lu...</td>\n","      <td>Pare pra pensar responda : Bolsonaro Lula venc...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Ninguém tem direito de explorar o jeito do pov...</td>\n","      <td>2022-08-18 22:38:57+00:00</td>\n","      <td>33374761</td>\n","      <td>1560395854887936000</td>\n","      <td>1560395854887936000</td>\n","      <td>ninguém tem direito de explorar o jeito do pov...</td>\n","      <td>[Ninguém, direito, explorar, jeito, povo, ador...</td>\n","      <td>Ninguém direito explorar jeito povo adorar Deu...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Dizer que eu não votei em 2018 é picaretagem a...</td>\n","      <td>2022-08-18 22:01:32+00:00</td>\n","      <td>33374761</td>\n","      <td>1560386438398898176</td>\n","      <td>1560386438398898176</td>\n","      <td>dizer que eu não votei em  é picaretagem absol...</td>\n","      <td>[Dizer, votei, 2018, picaretagem, absoluta, .,...</td>\n","      <td>Dizer votei 2018 picaretagem absoluta . O fiz ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  \\\n","0  Todo mundo viu esse papo de altíssimo nível co...   \n","1  É isso que a gente necessita: desarmar. Precis...   \n","2  Pare pra pensar e me responda: se Bolsonaro ou...   \n","3  Ninguém tem direito de explorar o jeito do pov...   \n","4  Dizer que eu não votei em 2018 é picaretagem a...   \n","\n","                 created_at  author_id                   id  \\\n","0 2022-08-19 01:31:22+00:00   33374761  1560439246913257472   \n","1 2022-08-18 22:41:15+00:00   33374761  1560396436294062080   \n","2 2022-08-18 22:41:15+00:00   33374761  1560396434725376000   \n","3 2022-08-18 22:38:57+00:00   33374761  1560395854887936000   \n","4 2022-08-18 22:01:32+00:00   33374761  1560386438398898176   \n","\n","       conversation_id                                        text_normal  \\\n","0  1560439246913257472  todo mundo viu esse papo de altíssimo nível co...   \n","1  1560396434725376000  é isso que a gente necessita desarmar precisam...   \n","2  1560396434725376000  pare pra pensar e me responda se bolsonaro ou ...   \n","3  1560395854887936000  ninguém tem direito de explorar o jeito do pov...   \n","4  1560386438398898176  dizer que eu não votei em  é picaretagem absol...   \n","\n","                                              tokens  \\\n","0  [Todo, mundo, viu, papo, altíssimo, nível, que...   \n","1  [É, gente, necessita, :, desarmar, ., Precisam...   \n","2  [Pare, pra, pensar, responda, :, Bolsonaro, Lu...   \n","3  [Ninguém, direito, explorar, jeito, povo, ador...   \n","4  [Dizer, votei, 2018, picaretagem, absoluta, .,...   \n","\n","                                        texto_tokens  \n","0  Todo mundo viu papo altíssimo nível querido @ ...  \n","1  É gente necessita : desarmar . Precisamos reco...  \n","2  Pare pra pensar responda : Bolsonaro Lula venc...  \n","3  Ninguém direito explorar jeito povo adorar Deu...  \n","4  Dizer votei 2018 picaretagem absoluta . O fiz ...  "]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"markdown","metadata":{"id":"ZV-mwXjWVoLT"},"source":["# Modelagem de Tópicos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VJBsIdssWQC3"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"HooJDbp4WERL"},"source":["*texto em itálico*# Análise de Sentimentos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ANENPKpmWQeE"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"wYl-0IqqWI6u"},"source":["# Similaridade de Textos"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"5LANdfj4WRBM"},"outputs":[],"source":["def monta_docs(df, coluna_alvo, grupos, candidatos):\n","    docs = []\n","    for grp in grupos:\n","        for cand in candidatos:\n","            df_filtrado = df[df['topico'] == grp and df['candidato'] == cand]\n","            texto = ' '.join(df_filtrado[coluna_alvo].to_list())\n","            docs.append(texto)\n"," \n","    return docs\n","\n","def vetoriza_docs(lista_docs):\n","    corpus_vetorizado = np.vectorize(lista_docs)\n","    return corpus_vetorizado\n","\n","def gera_matriz_tfidf(corpus_vetorizado):\n","    tf = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n","    matriz_tfidf = tf.fit_transform(corpus_vetorizado)\n","    return matriz_tfidf\n","\n","def similaridade_pares(matriz_tfidf):\n","    dict_docs_sim = cosine_similarity(matriz_tfidf)\n","    df_sim = pd.DataFrame(dict_docs_sim)\n","    return df_sim\n","\n","def calcula_similaridade(df, coluna_alvo, grupos, candidatos):\n","    lista_docs = monta_docs(df, coluna_alvo, grupos, candidatos)\n","    corpus_vetorizado = vetoriza_docs(lista_docs)\n","    matriz_tfidf = gera_matriz_tfidf(corpus_vetorizado)\n","    df_sim = similaridade_pares(matriz_tfidf)\n","\n","    return df_sim\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'norm_corpus' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/home/lucas/Documents/Repos/pln-2022.2/src/Projeto2-PLN.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/lucas/Documents/Repos/pln-2022.2/src/Projeto2-PLN.ipynb#ch0000014?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_extraction\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext\u001b[39;00m \u001b[39mimport\u001b[39;00m TfidfVectorizer\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/lucas/Documents/Repos/pln-2022.2/src/Projeto2-PLN.ipynb#ch0000014?line=2'>3</a>\u001b[0m tf \u001b[39m=\u001b[39m TfidfVectorizer(ngram_range\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m), min_df\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/lucas/Documents/Repos/pln-2022.2/src/Projeto2-PLN.ipynb#ch0000014?line=3'>4</a>\u001b[0m tfidf_matrix \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfit_transform(norm_corpus)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/lucas/Documents/Repos/pln-2022.2/src/Projeto2-PLN.ipynb#ch0000014?line=4'>5</a>\u001b[0m tfidf_matrix\u001b[39m.\u001b[39mshape\n","\u001b[0;31mNameError\u001b[0m: name 'norm_corpus' is not defined"]}],"source":["\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Projeto2-PLN.ipynb","provenance":[]},"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"},"kernelspec":{"display_name":"Python 3.9.5 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"}},"nbformat":4,"nbformat_minor":0}
