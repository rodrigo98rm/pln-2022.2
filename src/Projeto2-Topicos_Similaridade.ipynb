{"cells":[{"cell_type":"markdown","metadata":{"id":"dplAA4R5mRrE"},"source":["##Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1660869356185,"user":{"displayName":"Juliana Thomaz","userId":"10883141159324758422"},"user_tz":180},"id":"OWFK6d3QmRKE"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/lucas/.local/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import re\n","import pandas as pd\n","import json\n","import numpy as np\n","import seaborn as sns\n","import nltk\n","from bertopic import BERTopic"]},{"cell_type":"markdown","metadata":{"id":"muyhJsQRVfZH"},"source":["# Extra√ß√£o de Dados"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def df_tweets_candidatos(json_filename):\n","    df = pd.read_json(json_filename).drop(columns = ['replies'])\n","    return df\n","\n","\n","def df_tweets_respostas(json_filename):\n","    df = pd.read_json(json_filename).dropna().reset_index()[['replies']]\n","    ds = []\n","    for replies in df['replies'].to_list():\n","        for reply in replies:\n","            ds.append(reply)\n","\n","    reply_df = pd.DataFrame (ds).drop(columns = ['attachments'])\n","    return reply_df\n","\n","def df_tweets_cadidatos_respostas(json_filename):\n","    df_tweets_cand = df_tweets_candidatos(json_filename)\n","    df_tweets_reps = df_tweets_respostas(json_filename)\n","\n","    return (df_tweets_cand, df_tweets_reps)"]},{"cell_type":"markdown","metadata":{"id":"apymyF3WWswV"},"source":["# Pr√©-Processamento"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"3dHR9A7RWwZU"},"outputs":[{"name":"stdout","output_type":"stream","text":["N√∫mero de tweets: 300\n","\n","      author_id      conversation_id                created_at  \\\n","74   2670726740  1558834809882943488 2022-08-14 15:15:55+00:00   \n","286   128372940  1555964162181943296 2022-08-06 17:08:59+00:00   \n","252   128372940  1557892369990795264 2022-08-12 00:51:00+00:00   \n","11   2670726740  1560032266042019840 2022-08-17 22:34:10+00:00   \n","165    33374761  1559377178495787008 2022-08-16 03:11:05+00:00   \n","\n","                                                  text                   id  \\\n","74   Beag√°, semana que vem tem Lula na cidade! J√° r...  1558834809882943488   \n","286  - Hoje, em Recife / Pernambuco (06/08/2022). üáß...  1555964162181943296   \n","252  - O Brasil j√° tem sua carta pela democracia: a...  1557892373379702784   \n","11   Aten√ß√£o BH: amanh√£ tem ato na cidade! O evento...  1560032266042019840   \n","165  Estamos propondo um novo sistema previdenci√°ri...  1559377178495787008   \n","\n","     candidato  \n","74        lula  \n","286  bolsonaro  \n","252  bolsonaro  \n","11        lula  \n","165       ciro  \n"]}],"source":["tweets = df_tweets_candidatos('./datasets/dataset.json')\n","\n","\n","# Adicionar nomes dos candidatos no dataframe\n","for index, row in tweets.iterrows():\n","    candidato = ''\n","    if row.author_id == 2670726740:\n","      candidato = 'lula'\n","    elif row.author_id == 128372940:\n","      candidato = 'bolsonaro'\n","    elif row.author_id == 33374761:\n","      candidato = 'ciro'\n","    else:\n","      candidato = 'n/d'\n","    tweets.at[index, 'candidato'] = candidato\n","\n","tweets = tweets.sample(frac=1)\n","print(f'N√∫mero de tweets: {len(tweets)}\\n')\n","print(tweets.head())"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /home/lucas/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["nltk.download('stopwords')\n","pt_stop = set(nltk.corpus.stopwords.words('portuguese'))"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import re\n","from nltk.stem import WordNetLemmatizer\n","\n","stemmer = WordNetLemmatizer()\n","\n","def preprocess_text(document):\n","\n","        # removing urls\n","        document = re.sub(r'http\\S+', '', document)\n","\n","        # removing mentions\n","        document = re.sub(r'\\B@\\w+', '', document)\n","\n","        # remove all the special characters\n","        document = re.sub(r'\\W', ' ', str(document))\n","\n","        # remove all single characters\n","        document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n","\n","        # remove single characters from the start\n","        document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document)\n","\n","        # substituting multiple spaces with single space\n","        document = re.sub(r'\\s+', ' ', document, flags=re.I)\n","\n","        # removing prefixed 'b'\n","        document = re.sub(r'^b\\s+', '', document)\n","\n","        # converting to lowercase\n","        document = document.lower()\n","\n","        # lemmatization\n","        tokens = document.split()\n","        tokens = [stemmer.lemmatize(word) for word in tokens]\n","        tokens = [word for word in tokens if word not in pt_stop]\n","        tokens = [word for word in tokens if len(word) > 3]\n","\n","        return ' '.join(tokens)"]},{"cell_type":"markdown","metadata":{"id":"ZV-mwXjWVoLT"},"source":["# Modelagem de T√≥picos"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"VJBsIdssWQC3"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package omw-1.4 to /home/lucas/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n","[nltk_data] Downloading package wordnet to /home/lucas/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","nltk.download('omw-1.4')\n","nltk.download('wordnet')"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:13<00:00,  1.36s/it]\n","2022-08-25 21:43:42,103 - BERTopic - Transformed documents to Embeddings\n","2022-08-25 21:43:53,610 - BERTopic - Reduced dimensionality\n","2022-08-25 21:43:53,942 - BERTopic - Clustered reduced embeddings\n"]}],"source":["# create model \n","model = BERTopic(language=\"multilingual\", verbose=True, min_topic_size=3, top_n_words=10, calculate_probabilities=True)\n","\n","# convert to list \n","docs = tweets.text.to_list()\n","\n","# Pre-processamento\n","for i, doc in enumerate(docs):\n","    docs[i] = preprocess_text(doc)\n","\n","tweets_topic, probabilities = model.fit_transform(docs)"]},{"cell_type":"markdown","metadata":{},"source":["Adicionando o t√≥pico de cada tweet no Dataframe"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>author_id</th>\n","      <th>conversation_id</th>\n","      <th>created_at</th>\n","      <th>text</th>\n","      <th>id</th>\n","      <th>candidato</th>\n","      <th>topico</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>74</th>\n","      <td>2.670727e+09</td>\n","      <td>1.558835e+18</td>\n","      <td>2022-08-14 15:15:55+00:00</td>\n","      <td>Beag√°, semana que vem tem Lula na cidade! J√° r...</td>\n","      <td>1.558835e+18</td>\n","      <td>lula</td>\n","      <td>1_melhor_brasildaesperan√ßa_esperan√ßa_brasil</td>\n","    </tr>\n","    <tr>\n","      <th>286</th>\n","      <td>1.283729e+08</td>\n","      <td>1.555964e+18</td>\n","      <td>2022-08-06 17:08:59+00:00</td>\n","      <td>- Hoje, em Recife / Pernambuco (06/08/2022). üáß...</td>\n","      <td>1.555964e+18</td>\n","      <td>bolsonaro</td>\n","      <td>13_central_pergunta_cironorodaviva_banco</td>\n","    </tr>\n","    <tr>\n","      <th>252</th>\n","      <td>1.283729e+08</td>\n","      <td>1.557892e+18</td>\n","      <td>2022-08-12 00:51:00+00:00</td>\n","      <td>- O Brasil j√° tem sua carta pela democracia: a...</td>\n","      <td>1.557892e+18</td>\n","      <td>bolsonaro</td>\n","      <td>21_aux√≠lio_emergencial_dezembro_agora</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2.670727e+09</td>\n","      <td>1.560032e+18</td>\n","      <td>2022-08-17 22:34:10+00:00</td>\n","      <td>Aten√ß√£o BH: amanh√£ tem ato na cidade! O evento...</td>\n","      <td>1.560032e+18</td>\n","      <td>lula</td>\n","      <td>7_elei√ß√£o_voto_falar_caf√©</td>\n","    </tr>\n","    <tr>\n","      <th>165</th>\n","      <td>3.337476e+07</td>\n","      <td>1.559377e+18</td>\n","      <td>2022-08-16 03:11:05+00:00</td>\n","      <td>Estamos propondo um novo sistema previdenci√°ri...</td>\n","      <td>1.559377e+18</td>\n","      <td>ciro</td>\n","      <td>1_melhor_brasildaesperan√ßa_esperan√ßa_brasil</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        author_id  conversation_id                created_at  \\\n","74   2.670727e+09     1.558835e+18 2022-08-14 15:15:55+00:00   \n","286  1.283729e+08     1.555964e+18 2022-08-06 17:08:59+00:00   \n","252  1.283729e+08     1.557892e+18 2022-08-12 00:51:00+00:00   \n","11   2.670727e+09     1.560032e+18 2022-08-17 22:34:10+00:00   \n","165  3.337476e+07     1.559377e+18 2022-08-16 03:11:05+00:00   \n","\n","                                                  text            id  \\\n","74   Beag√°, semana que vem tem Lula na cidade! J√° r...  1.558835e+18   \n","286  - Hoje, em Recife / Pernambuco (06/08/2022). üáß...  1.555964e+18   \n","252  - O Brasil j√° tem sua carta pela democracia: a...  1.557892e+18   \n","11   Aten√ß√£o BH: amanh√£ tem ato na cidade! O evento...  1.560032e+18   \n","165  Estamos propondo um novo sistema previdenci√°ri...  1.559377e+18   \n","\n","     candidato                                       topico  \n","74        lula  1_melhor_brasildaesperan√ßa_esperan√ßa_brasil  \n","286  bolsonaro     13_central_pergunta_cironorodaviva_banco  \n","252  bolsonaro        21_aux√≠lio_emergencial_dezembro_agora  \n","11        lula                    7_elei√ß√£o_voto_falar_caf√©  \n","165       ciro  1_melhor_brasildaesperan√ßa_esperan√ßa_brasil  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["topic_names = model.generate_topic_labels(nr_words=4)\n","\n","# Array indicando o t√≥pico de cada tweet (num√©rico -> √≠ndice do array \"topic_names\" + 1)\n","# print(tweets_topic)\n","# Array com todos os t√≥picos nomeados\n","# print(topic_names)\n","\n","for index, tweet_topic in enumerate(tweets_topic):\n","    tweets.at[index + 1, 'topico'] = topic_names[tweet_topic + 1]\n","\n","tweets.head()"]},{"cell_type":"markdown","metadata":{},"source":["Abaixo, os t√≥picos identificados entre todos os tweets"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["    Topic  Count                                               Name\n","0      -1     46                      -1_ciro_brasil_lula_reelei√ß√£o\n","1       0     25                       0_luladay_noite_gettr_baixar\n","2       1     22        1_melhor_brasildaesperan√ßa_esperan√ßa_brasil\n","3       2     17                2_milh√µes_fam√≠lias_safra_desemprego\n","4       3     16                        3_deus_crist√£os_crime_irm√£o\n","5       4     14                    4_pequenos_custou_quanto_b√°sico\n","6       5     14               5_redu√ß√£o_energia_combust√≠veis_pre√ßo\n","7       6     14                        6_link_lula_equipelula_vivo\n","8       7     11                          7_elei√ß√£o_voto_falar_caf√©\n","9       8      9            8_saudades_democracia_carta_democr√°tico\n","10      9      8                 9_programa_renda_m√≠nima_distribuir\n","11     10      7           10_quer_merecemos_responsabilidade_guiar\n","12     11      7                          11_todos_vivo_vice_beonce\n","13     12      7              12_est√≠mulo_competi√ß√µes_comit√™_provou\n","14     13      7           13_central_pergunta_cironorodaviva_banco\n","15     14      6                     14_campanha_mudar_in√≠cio_ficha\n","16     15      6             15_francisco_transposi√ß√£o_abra√ßo_todos\n","17     16      6                       16_rota_prefeito_junto_amigo\n","18     17      6                           17_2022_monte_claro_giro\n","19     18      6         18_recuperar_precisamos_restaurar_empregos\n","20     19      6                     19_juros_entregou_maior_guerra\n","21     20      5                20_garantido_governo_programa_renda\n","22     21      5              21_aux√≠lio_emergencial_dezembro_agora\n","23     22      5  22_reconstruirmos_candidato_brasildaesperan√ßa_...\n","24     23      5                23_corrup√ß√£o_chamar_errado_pol√≠tica\n","25     24      5               24_entenda_maconha_drogas_organizado\n","26     25      5      25_paix√µes_√≥dios_despolitizadas_oportunidades\n","27     26      4                     26_sobre_golpe_defesa_mulheres\n","28     27      3                    27_pernas_cada_brasileiro_virem\n","29     28      3            28_jair_bolsonaro_thiago_pronunciamento\n"]}],"source":["freq = model.get_topic_info()\n","print(freq)"]},{"cell_type":"markdown","metadata":{"id":"HooJDbp4WERL"},"source":["# An√°lise de Sentimentos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ANENPKpmWQeE"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"wYl-0IqqWI6u"},"source":["# Similaridade de Textos"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"5LANdfj4WRBM"},"outputs":[],"source":["def monta_docs_tweets(df, topico, coluna_alvo, candidatos):\n","    lista_tweets = []\n","    #df_topico = df[df['topico'] == topico]\n","    df_topico = df\n","\n","    for cand in candidatos:\n","        df_cand = df_topico[df_topico['candidato'] == cand]\n","        lista_tweets_cand = df_cand[coluna_alvo].to_list()\n","        lista_tweets.append(lista_tweets_cand)\n","    \n","    docs = np.concatenate(lista_tweets)\n","    return docs\n","\n","def monta_docs_concat_topico(df, topico, coluna_alvo, candidatos):\n","    docs = []\n","    df_topico = df[(df['topico'] == topico)]\n","    for cand in candidatos:\n","        df_topico_cand = df_topico[df_topico['candidato'] == cand]\n","        texto = ' '.join(df_topico_cand[coluna_alvo].to_list())\n","        docs.append(texto)\n","    return docs\n","\n","\n","def monta_docs_concat_candidato(df, coluna_alvo, candidatos):\n","    docs = []\n","    for cand in candidatos:\n","        df_cand = df[df['candidato'] == cand]\n","        texto = ' '.join(df_cand[coluna_alvo].to_list())\n","        docs.append(texto)\n","    return docs\n","\n","stop_words_ptbr = nltk.corpus.stopwords.words('portuguese')\n","\n","def normaliza_tweet(tweet):\n","    tweet = re.sub(r'[^a-zA-Z0-9\\s]', '', tweet, re.I|re.A)\n","    tweet = tweet.lower()\n","    tweet = tweet.strip()\n","    tokens = nltk.word_tokenize(tweet)\n","    tokens_filtrados = [token for token in tokens if token not in stop_words_ptbr]\n","    tweet_tokens = ' '.join(tokens_filtrados)\n","    return tweet_tokens\n","\n","def vetoriza_docs(lista_docs):\n","    corpus_vetorizado = np.vectorize(lista_docs)\n","    return corpus_vetorizado\n","\n","def gera_matriz_tfidf(corpus_vetorizado):\n","    tf = TfidfVectorizer(ngram_range=(1, 2), min_df=1)\n","    matriz_tfidf = tf.fit_transform(corpus_vetorizado)\n","    return matriz_tfidf\n","\n","def similaridade_pares(matriz_tfidf):\n","    dict_docs_sim = cosine_similarity(matriz_tfidf)\n","    df_sim = pd.DataFrame(dict_docs_sim)\n","    return df_sim\n","\n","def renomear_colunas(df, candidatos):\n","    df.columns = candidatos\n","    return df\n","\n","def calcula_similaridade_topico(df, topico, coluna_alvo, candidatos):\n","    lista_docs = monta_docs_concat_topico(df, topico, coluna_alvo, candidatos)\n","    normaliza_tweets = np.vectorize(normaliza_tweet)\n","    corpus_normalizado = normaliza_tweets(lista_docs)\n","    matriz_tfidf = gera_matriz_tfidf(corpus_normalizado)\n","    df_sim = similaridade_pares(matriz_tfidf)\n","    df_sim_cands = renomear_colunas(df_sim, candidatos)\n","\n","    return df_sim_cands\n","\n","def calcula_similaridade_candidatos(df, coluna_alvo, candidatos):\n","    lista_docs = monta_docs_concat_candidato(df, coluna_alvo, candidatos)\n","    normaliza_tweets = np.vectorize(normaliza_tweet)\n","    corpus_normalizado = normaliza_tweets(lista_docs)\n","    matriz_tfidf = gera_matriz_tfidf(corpus_normalizado)\n","    df_sim = similaridade_pares(matriz_tfidf)\n","    df_sim_cands = renomear_colunas(df_sim, candidatos)\n","\n","    return df_sim\n","\n","def calcula_similaridade_topicos(df, topicos, coluna_alvo, candidatos):\n","    dfs_sim = []\n","    for topico in topicos:\n","        dfs_sim.append(calcula_similaridade_topico(df, topico, coluna_alvo, candidatos))\n","        \n","    sim_dict = dict(zip(topicos, dfs_sim))\n","    return sim_dict"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["['-1_ciro_brasil_lula_reelei√ß√£o',\n"," '0_luladay_noite_gettr_baixar',\n"," '1_melhor_brasildaesperan√ßa_esperan√ßa_brasil',\n"," '2_milh√µes_fam√≠lias_safra_desemprego']"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df_freq = model.get_topic_info()\n","topicos_mais_frequentes = df_freq['Name'].to_list()[0:4]\n","topicos_mais_frequentes"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Para t√≥pico = -1_ciro_brasil_lula_reelei√ß√£o\n","       lula  bolsonaro      ciro\n","0  1.000000   0.012569  0.070754\n","1  0.012569   1.000000  0.028200\n","2  0.070754   0.028200  1.000000\n","----------------------------------\n","Para t√≥pico = 0_luladay_noite_gettr_baixar\n","       lula  bolsonaro      ciro\n","0  1.000000   0.025657  0.073263\n","1  0.025657   1.000000  0.014557\n","2  0.073263   0.014557  1.000000\n","----------------------------------\n","Para t√≥pico = 1_melhor_brasildaesperan√ßa_esperan√ßa_brasil\n","       lula  bolsonaro      ciro\n","0  1.000000   0.007351  0.041668\n","1  0.007351   1.000000  0.020782\n","2  0.041668   0.020782  1.000000\n","----------------------------------\n","Para t√≥pico = 2_milh√µes_fam√≠lias_safra_desemprego\n","       lula  bolsonaro      ciro\n","0  1.000000   0.007339  0.024608\n","1  0.007339   1.000000  0.011247\n","2  0.024608   0.011247  1.000000\n","----------------------------------\n"]}],"source":["candidatos = [\"lula\", \"bolsonaro\", \"ciro\"]\n","analise_similaridade = calcula_similaridade_topicos(tweets, topicos_mais_frequentes, \"text\", candidatos)\n","for topico in analise_similaridade.keys():\n","    print(f\"Para t√≥pico = {topico}\")\n","    print(analise_similaridade[topico])\n","    print('----------------------------------')"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>lula</th>\n","      <th>bolsonaro</th>\n","      <th>ciro</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.000000</td>\n","      <td>0.333256</td>\n","      <td>0.365497</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.333256</td>\n","      <td>1.000000</td>\n","      <td>0.293330</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.365497</td>\n","      <td>0.293330</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       lula  bolsonaro      ciro\n","0  1.000000   0.333256  0.365497\n","1  0.333256   1.000000  0.293330\n","2  0.365497   0.293330  1.000000"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["analise_sim_cand = calcula_similaridade_candidatos(tweets, \"text\", candidatos)\n","analise_sim_cand"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Projeto2-PLN.ipynb","provenance":[]},"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"},"kernelspec":{"display_name":"Python 3.9.5 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"}},"nbformat":4,"nbformat_minor":0}
