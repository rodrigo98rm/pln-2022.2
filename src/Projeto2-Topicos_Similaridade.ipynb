{"cells":[{"cell_type":"markdown","metadata":{"id":"dplAA4R5mRrE"},"source":["##Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1660869356185,"user":{"displayName":"Juliana Thomaz","userId":"10883141159324758422"},"user_tz":180},"id":"OWFK6d3QmRKE"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/rodrigo98rm/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","2022-08-25 22:23:57.496130: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n","2022-08-25 22:23:57.496148: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"]}],"source":["import re\n","import pandas as pd\n","import json\n","import numpy as np\n","import seaborn as sns\n","import nltk\n","from bertopic import BERTopic"]},{"cell_type":"markdown","metadata":{"id":"muyhJsQRVfZH"},"source":["# Extração de Dados"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def df_tweets_candidatos(json_filename):\n","    df = pd.read_json(json_filename).drop(columns = ['replies'])\n","    return df\n","\n","\n","def df_tweets_respostas(json_filename):\n","    df = pd.read_json(json_filename).dropna().reset_index()[['replies']]\n","    ds = []\n","    for replies in df['replies'].to_list():\n","        for reply in replies:\n","            ds.append(reply)\n","\n","    reply_df = pd.DataFrame (ds).drop(columns = ['attachments'])\n","    return reply_df\n","\n","def df_tweets_cadidatos_respostas(json_filename):\n","    df_tweets_cand = df_tweets_candidatos(json_filename)\n","    df_tweets_reps = df_tweets_respostas(json_filename)\n","\n","    return (df_tweets_cand, df_tweets_reps)"]},{"cell_type":"markdown","metadata":{"id":"apymyF3WWswV"},"source":["# Pré-Processamento"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"3dHR9A7RWwZU"},"outputs":[{"name":"stdout","output_type":"stream","text":["Número de tweets: 300\n","\n","    author_id      conversation_id                created_at  \\\n","0  2670726740  1560319888643719168 2022-08-18 17:37:05+00:00   \n","1  2670726740  1560299315905515520 2022-08-18 16:15:20+00:00   \n","2  2670726740  1560285152282034176 2022-08-18 15:19:03+00:00   \n","3  2670726740  1560266077329694720 2022-08-18 14:03:15+00:00   \n","4  2670726740  1560248955753095168 2022-08-18 12:55:13+00:00   \n","\n","                                                text                   id  \\\n","0  As pessoas pensam que o sucesso dos nossos gov...  1560319888643719168   \n","1  Já em Belo Horizonte para o primeiro comício d...  1560299315905515520   \n","2  Ontem Lula recebeu a visita de representantes ...  1560285152282034176   \n","3  RT @verdadenarede: Damares condenada! No final...  1560266077329694720   \n","4                      Nove. https://t.co/hfMesT3LHq  1560248955753095168   \n","\n","  candidato  \n","0      lula  \n","1      lula  \n","2      lula  \n","3      lula  \n","4      lula  \n"]}],"source":["tweets = df_tweets_candidatos('./datasets/dataset.json')\n","\n","\n","# Adicionar nomes dos candidatos no dataframe\n","for index, row in tweets.iterrows():\n","    candidato = ''\n","    if row.author_id == 2670726740:\n","      candidato = 'lula'\n","    elif row.author_id == 128372940:\n","      candidato = 'bolsonaro'\n","    elif row.author_id == 33374761:\n","      candidato = 'ciro'\n","    else:\n","      candidato = 'n/d'\n","    tweets.at[index, 'candidato'] = candidato\n","\n","print(f'Número de tweets: {len(tweets)}\\n')\n","print(tweets.head())"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     /home/rodrigo98rm/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["nltk.download('stopwords')\n","pt_stop = set(nltk.corpus.stopwords.words('portuguese'))"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import re\n","from nltk.stem import WordNetLemmatizer\n","\n","stemmer = WordNetLemmatizer()\n","\n","def preprocess_text(document):\n","\n","        # removing urls\n","        document = re.sub(r'http\\S+', '', document)\n","\n","        # removing mentions\n","        document = re.sub(r'\\B@\\w+', '', document)\n","\n","        # remove all the special characters\n","        document = re.sub(r'\\W', ' ', str(document))\n","\n","        # remove all single characters\n","        document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n","\n","        # remove single characters from the start\n","        document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document)\n","\n","        # substituting multiple spaces with single space\n","        document = re.sub(r'\\s+', ' ', document, flags=re.I)\n","\n","        # removing prefixed 'b'\n","        document = re.sub(r'^b\\s+', '', document)\n","\n","        # converting to lowercase\n","        document = document.lower()\n","\n","        # lemmatization\n","        tokens = document.split()\n","        tokens = [stemmer.lemmatize(word) for word in tokens]\n","        tokens = [word for word in tokens if word not in pt_stop]\n","        tokens = [word for word in tokens if len(word) > 3]\n","\n","        return ' '.join(tokens)"]},{"cell_type":"markdown","metadata":{"id":"ZV-mwXjWVoLT"},"source":["# Modelagem de Tópicos"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"VJBsIdssWQC3"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package omw-1.4 to\n","[nltk_data]     /home/rodrigo98rm/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     /home/rodrigo98rm/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","nltk.download('omw-1.4')\n","nltk.download('wordnet')"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Batches: 100%|██████████| 10/10 [00:00<00:00, 30.54it/s]\n","2022-08-25 22:24:03,007 - BERTopic - Transformed documents to Embeddings\n","2022-08-25 22:24:07,383 - BERTopic - Reduced dimensionality\n","2022-08-25 22:24:07,411 - BERTopic - Clustered reduced embeddings\n"]}],"source":["# create model \n","model = BERTopic(language=\"multilingual\", verbose=True, min_topic_size=3, top_n_words=10, calculate_probabilities=True)\n","\n","# convert to list \n","docs = tweets.text.to_list()\n","\n","# Pre-processamento\n","for i, doc in enumerate(docs):\n","    docs[i] = preprocess_text(doc)\n","\n","tweets_topic, probabilities = model.fit_transform(docs)"]},{"cell_type":"markdown","metadata":{},"source":["Adicionando o tópico de cada tweet no Dataframe"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>author_id</th>\n","      <th>conversation_id</th>\n","      <th>created_at</th>\n","      <th>text</th>\n","      <th>id</th>\n","      <th>candidato</th>\n","      <th>topico</th>\n","      <th>processed_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2670726740</td>\n","      <td>1560319888643719168</td>\n","      <td>2022-08-18 17:37:05+00:00</td>\n","      <td>As pessoas pensam que o sucesso dos nossos gov...</td>\n","      <td>1560319888643719168</td>\n","      <td>lula</td>\n","      <td>6_brasil_país_brasildaesperança_democracia</td>\n","      <td>pessoas pensam sucesso governos bolsa família ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2670726740</td>\n","      <td>1560299315905515520</td>\n","      <td>2022-08-18 16:15:20+00:00</td>\n","      <td>Já em Belo Horizonte para o primeiro comício d...</td>\n","      <td>1560299315905515520</td>\n","      <td>lula</td>\n","      <td>11_campanha_mudar_primeiro_início</td>\n","      <td>belo horizonte primeiro comício campanha próxi...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2670726740</td>\n","      <td>1560285152282034176</td>\n","      <td>2022-08-18 15:19:03+00:00</td>\n","      <td>Ontem Lula recebeu a visita de representantes ...</td>\n","      <td>1560285152282034176</td>\n","      <td>lula</td>\n","      <td>14_cironorodaviva_pergunta_ciro_responde</td>\n","      <td>ontem lula recebeu visita representantes parti...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2670726740</td>\n","      <td>1560266077329694720</td>\n","      <td>2022-08-18 14:03:15+00:00</td>\n","      <td>RT @verdadenarede: Damares condenada! No final...</td>\n","      <td>1560266077329694720</td>\n","      <td>lula</td>\n","      <td>-1_ciro_presidente_brasil_reeleição</td>\n","      <td>damares condenada final noite desta quarta jus...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2670726740</td>\n","      <td>1560248955753095168</td>\n","      <td>2022-08-18 12:55:13+00:00</td>\n","      <td>Nove. https://t.co/hfMesT3LHq</td>\n","      <td>1560248955753095168</td>\n","      <td>lula</td>\n","      <td>1_luladay_noite_gettr_baixar</td>\n","      <td>nove</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>295</th>\n","      <td>128372940</td>\n","      <td>1555565663942770688</td>\n","      <td>2022-08-05 14:45:29+00:00</td>\n","      <td>- Independentemente de preferências ideológica...</td>\n","      <td>1555565663942770688</td>\n","      <td>bolsonaro</td>\n","      <td>2_esperança_melhor_brasildaesperança_brasil</td>\n","      <td>independentemente preferências ideológicas soa...</td>\n","    </tr>\n","    <tr>\n","      <th>296</th>\n","      <td>128372940</td>\n","      <td>1555537798807044096</td>\n","      <td>2022-08-05 12:54:46+00:00</td>\n","      <td>RT @fabiofaria: Realizamos a 1ª reunião do Gov...</td>\n","      <td>1555537798807044096</td>\n","      <td>bolsonaro</td>\n","      <td>14_cironorodaviva_pergunta_ciro_responde</td>\n","      <td>realizamos reunião federal ambiente virtual ap...</td>\n","    </tr>\n","    <tr>\n","      <th>297</th>\n","      <td>128372940</td>\n","      <td>1555521006051155968</td>\n","      <td>2022-08-05 11:48:03+00:00</td>\n","      <td>- A operação representa mais de R$ 20 milhões ...</td>\n","      <td>1555521008248971264</td>\n","      <td>bolsonaro</td>\n","      <td>21_entenda_maconha_drogas_organizado</td>\n","      <td>operação representa milhões prejuízo tráfico d...</td>\n","    </tr>\n","    <tr>\n","      <th>298</th>\n","      <td>128372940</td>\n","      <td>1555521006051155968</td>\n","      <td>2022-08-05 11:48:02+00:00</td>\n","      <td>- Mesmo que a Polícia esteja impedida de reali...</td>\n","      <td>1555521006051155968</td>\n","      <td>bolsonaro</td>\n","      <td>21_entenda_maconha_drogas_organizado</td>\n","      <td>polícia impedida realizar certas operações rec...</td>\n","    </tr>\n","    <tr>\n","      <th>299</th>\n","      <td>128372940</td>\n","      <td>1555376931058622464</td>\n","      <td>2022-08-05 02:15:32+00:00</td>\n","      <td>- Soube que o PT agora reza o Pai Nosso e usa ...</td>\n","      <td>1555376931058622464</td>\n","      <td>bolsonaro</td>\n","      <td>8_carta_saudades_democracia_drogas</td>\n","      <td>soube agora reza bandeiras brasil eventos come...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>300 rows × 8 columns</p>\n","</div>"],"text/plain":["      author_id      conversation_id                created_at  \\\n","0    2670726740  1560319888643719168 2022-08-18 17:37:05+00:00   \n","1    2670726740  1560299315905515520 2022-08-18 16:15:20+00:00   \n","2    2670726740  1560285152282034176 2022-08-18 15:19:03+00:00   \n","3    2670726740  1560266077329694720 2022-08-18 14:03:15+00:00   \n","4    2670726740  1560248955753095168 2022-08-18 12:55:13+00:00   \n","..          ...                  ...                       ...   \n","295   128372940  1555565663942770688 2022-08-05 14:45:29+00:00   \n","296   128372940  1555537798807044096 2022-08-05 12:54:46+00:00   \n","297   128372940  1555521006051155968 2022-08-05 11:48:03+00:00   \n","298   128372940  1555521006051155968 2022-08-05 11:48:02+00:00   \n","299   128372940  1555376931058622464 2022-08-05 02:15:32+00:00   \n","\n","                                                  text                   id  \\\n","0    As pessoas pensam que o sucesso dos nossos gov...  1560319888643719168   \n","1    Já em Belo Horizonte para o primeiro comício d...  1560299315905515520   \n","2    Ontem Lula recebeu a visita de representantes ...  1560285152282034176   \n","3    RT @verdadenarede: Damares condenada! No final...  1560266077329694720   \n","4                        Nove. https://t.co/hfMesT3LHq  1560248955753095168   \n","..                                                 ...                  ...   \n","295  - Independentemente de preferências ideológica...  1555565663942770688   \n","296  RT @fabiofaria: Realizamos a 1ª reunião do Gov...  1555537798807044096   \n","297  - A operação representa mais de R$ 20 milhões ...  1555521008248971264   \n","298  - Mesmo que a Polícia esteja impedida de reali...  1555521006051155968   \n","299  - Soube que o PT agora reza o Pai Nosso e usa ...  1555376931058622464   \n","\n","     candidato                                       topico  \\\n","0         lula   6_brasil_país_brasildaesperança_democracia   \n","1         lula            11_campanha_mudar_primeiro_início   \n","2         lula     14_cironorodaviva_pergunta_ciro_responde   \n","3         lula          -1_ciro_presidente_brasil_reeleição   \n","4         lula                 1_luladay_noite_gettr_baixar   \n","..         ...                                          ...   \n","295  bolsonaro  2_esperança_melhor_brasildaesperança_brasil   \n","296  bolsonaro     14_cironorodaviva_pergunta_ciro_responde   \n","297  bolsonaro         21_entenda_maconha_drogas_organizado   \n","298  bolsonaro         21_entenda_maconha_drogas_organizado   \n","299  bolsonaro           8_carta_saudades_democracia_drogas   \n","\n","                                        processed_text  \n","0    pessoas pensam sucesso governos bolsa família ...  \n","1    belo horizonte primeiro comício campanha próxi...  \n","2    ontem lula recebeu visita representantes parti...  \n","3    damares condenada final noite desta quarta jus...  \n","4                                                 nove  \n","..                                                 ...  \n","295  independentemente preferências ideológicas soa...  \n","296  realizamos reunião federal ambiente virtual ap...  \n","297  operação representa milhões prejuízo tráfico d...  \n","298  polícia impedida realizar certas operações rec...  \n","299  soube agora reza bandeiras brasil eventos come...  \n","\n","[300 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["topic_names = model.generate_topic_labels(nr_words=4)\n","\n","# Array indicando o tópico de cada tweet (numérico -> índice do array \"topic_names\" + 1)\n","# print(tweets_topic)\n","# Array com todos os tópicos nomeados\n","# print(topic_names)\n","\n","# print(docs)\n","\n","\n","for index, tweet_topic in enumerate(tweets_topic):\n","    tweets.at[index, 'topico'] = topic_names[tweet_topic+1]\n","    tweets.at[index, 'processed_text'] = docs[index]\n","\n","# DEBUG\n","# display(tweets)\n","# tweets.to_csv('/home/rodrigo98rm/Documents/ufabc/pln/projeto-2/pln-2022.2/src/output/dataframe.csv', sep='\\t', encoding='utf-8')"]},{"cell_type":"markdown","metadata":{},"source":["Abaixo, os tópicos identificados entre todos os tweets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["freq = model.get_topic_info()\n","print(freq)"]},{"cell_type":"markdown","metadata":{"id":"HooJDbp4WERL"},"source":["# Análise de Sentimentos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ANENPKpmWQeE"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"wYl-0IqqWI6u"},"source":["# Similaridade de Textos"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5LANdfj4WRBM"},"outputs":[],"source":["def monta_docs_tweets(df, topico, coluna_alvo, candidatos):\n","    lista_tweets = []\n","    #df_topico = df[df['topico'] == topico]\n","    df_topico = df\n","\n","    for cand in candidatos:\n","        df_cand = df_topico[df_topico['candidato'] == cand]\n","        lista_tweets_cand = df_cand[coluna_alvo].to_list()\n","        lista_tweets.append(lista_tweets_cand)\n","    \n","    docs = np.concatenate(lista_tweets)\n","    return docs\n","\n","def monta_docs_concat_topico(df, topico, coluna_alvo, candidatos):\n","    docs = []\n","    df_topico = df[(df['topico'] == topico)]\n","    for cand in candidatos:\n","        df_topico_cand = df_topico[df_topico['candidato'] == cand]\n","        texto = ' '.join(df_topico_cand[coluna_alvo].to_list())\n","        docs.append(texto)\n","    return docs\n","\n","\n","def monta_docs_concat_candidato(df, coluna_alvo, candidatos):\n","    docs = []\n","    for cand in candidatos:\n","        df_cand = df[df['candidato'] == cand]\n","        texto = ' '.join(df_cand[coluna_alvo].to_list())\n","        docs.append(texto)\n","    return docs\n","\n","stop_words_ptbr = nltk.corpus.stopwords.words('portuguese')\n","\n","def normaliza_tweet(tweet):\n","    tweet = re.sub(r'[^a-zA-Z0-9\\s]', '', tweet, re.I|re.A)\n","    tweet = tweet.lower()\n","    tweet = tweet.strip()\n","    tokens = nltk.word_tokenize(tweet)\n","    tokens_filtrados = [token for token in tokens if token not in stop_words_ptbr]\n","    tweet_tokens = ' '.join(tokens_filtrados)\n","    return tweet_tokens\n","\n","def vetoriza_docs(lista_docs):\n","    corpus_vetorizado = np.vectorize(lista_docs)\n","    return corpus_vetorizado\n","\n","def gera_matriz_tfidf(corpus_vetorizado):\n","    tf = TfidfVectorizer(ngram_range=(1, 2), min_df=1)\n","    matriz_tfidf = tf.fit_transform(corpus_vetorizado)\n","    return matriz_tfidf\n","\n","def similaridade_pares(matriz_tfidf):\n","    dict_docs_sim = cosine_similarity(matriz_tfidf)\n","    df_sim = pd.DataFrame(dict_docs_sim)\n","    return df_sim\n","\n","def renomear_colunas(df, candidatos):\n","    df.columns = candidatos\n","    return df\n","\n","def calcula_similaridade_topico(df, topico, coluna_alvo, candidatos):\n","    lista_docs = monta_docs_concat_topico(df, topico, coluna_alvo, candidatos)\n","    normaliza_tweets = np.vectorize(normaliza_tweet)\n","    corpus_normalizado = normaliza_tweets(lista_docs)\n","    matriz_tfidf = gera_matriz_tfidf(corpus_normalizado)\n","    df_sim = similaridade_pares(matriz_tfidf)\n","    df_sim_cands = renomear_colunas(df_sim, candidatos)\n","\n","    return df_sim_cands\n","\n","def calcula_similaridade_candidatos(df, coluna_alvo, candidatos):\n","    lista_docs = monta_docs_concat_candidato(df, coluna_alvo, candidatos)\n","    normaliza_tweets = np.vectorize(normaliza_tweet)\n","    corpus_normalizado = normaliza_tweets(lista_docs)\n","    matriz_tfidf = gera_matriz_tfidf(corpus_normalizado)\n","    df_sim = similaridade_pares(matriz_tfidf)\n","    df_sim_cands = renomear_colunas(df_sim, candidatos)\n","\n","    return df_sim\n","\n","def calcula_similaridade_topicos(df, topicos, coluna_alvo, candidatos):\n","    dfs_sim = []\n","    for topico in topicos:\n","        dfs_sim.append(calcula_similaridade_topico(df, topico, coluna_alvo, candidatos))\n","        \n","    sim_dict = dict(zip(topicos, dfs_sim))\n","    return sim_dict"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_freq = model.get_topic_info()\n","topicos_mais_frequentes = df_freq['Name'].to_list()[0:4]\n","topicos_mais_frequentes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["candidatos = [\"lula\", \"bolsonaro\", \"ciro\"]\n","analise_similaridade = calcula_similaridade_topicos(tweets, topicos_mais_frequentes, \"text\", candidatos)\n","for topico in analise_similaridade.keys():\n","    print(f\"Para tópico = {topico}\")\n","    print(analise_similaridade[topico])\n","    print('----------------------------------')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["analise_sim_cand = calcula_similaridade_candidatos(tweets, \"text\", candidatos)\n","analise_sim_cand"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Projeto2-PLN.ipynb","provenance":[]},"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"},"kernelspec":{"display_name":"Python 3.9.5 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}
