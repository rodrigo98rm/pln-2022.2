{"cells":[{"cell_type":"markdown","metadata":{"id":"dplAA4R5mRrE"},"source":["##Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1660869356185,"user":{"displayName":"Juliana Thomaz","userId":"10883141159324758422"},"user_tz":180},"id":"OWFK6d3QmRKE"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/lucas/.local/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import re\n","import pandas as pd\n","import json\n","import numpy as np\n","import seaborn as sns\n","import nltk\n","from bertopic import BERTopic"]},{"cell_type":"markdown","metadata":{"id":"muyhJsQRVfZH"},"source":["# Extração de Dados"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def df_tweets_candidatos(json_filename):\n","    df = pd.read_json(json_filename).drop(columns = ['replies'])\n","    return df\n","\n","\n","def df_tweets_respostas(json_filename):\n","    df = pd.read_json(json_filename).dropna().reset_index()[['replies']]\n","    ds = []\n","    for replies in df['replies'].to_list():\n","        for reply in replies:\n","            ds.append(reply)\n","\n","    reply_df = pd.DataFrame (ds).drop(columns = ['attachments'])\n","    return reply_df\n","\n","def df_tweets_cadidatos_respostas(json_filename):\n","    df_tweets_cand = df_tweets_candidatos(json_filename)\n","    df_tweets_reps = df_tweets_respostas(json_filename)\n","\n","    return (df_tweets_cand, df_tweets_reps)"]},{"cell_type":"markdown","metadata":{"id":"apymyF3WWswV"},"source":["# Pré-Processamento"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"3dHR9A7RWwZU"},"outputs":[{"name":"stdout","output_type":"stream","text":["Número de tweets: 300\n","\n","      author_id      conversation_id                created_at  \\\n","102    33374761  1560396434725376000 2022-08-18 22:41:15+00:00   \n","60   2670726740  1559313079334322176 2022-08-15 22:56:23+00:00   \n","70   2670726740  1558948211250937856 2022-08-14 22:46:32+00:00   \n","241   128372940  1558491746102906880 2022-08-13 16:32:42+00:00   \n","256   128372940  1557765109094797312 2022-08-11 16:32:40+00:00   \n","\n","                                                  text                   id  \\\n","102  Pare pra pensar e me responda: se Bolsonaro ou...  1560396434725376000   \n","60   Nós nordestinos, quando a gente se perde, a ge...  1559313079334322176   \n","70   Bolsonaro tenta se aproveitar do PIX, mas na r...  1558948211250937856   \n","241  - Agradeço aos mais de 450 mil espectadores qu...  1558491746102906880   \n","256  - A redução representa queda de R$ 0,22 por li...  1557766961546788864   \n","\n","     candidato  \n","102       ciro  \n","60        lula  \n","70        lula  \n","241  bolsonaro  \n","256  bolsonaro  \n"]}],"source":["tweets = df_tweets_candidatos('./datasets/dataset.json')\n","\n","\n","# Adicionar nomes dos candidatos no dataframe\n","for index, row in tweets.iterrows():\n","    candidato = ''\n","    if row.author_id == 2670726740:\n","      candidato = 'lula'\n","    elif row.author_id == 128372940:\n","      candidato = 'bolsonaro'\n","    elif row.author_id == 33374761:\n","      candidato = 'ciro'\n","    else:\n","      candidato = 'n/d'\n","    tweets.at[index, 'candidato'] = candidato\n","\n","tweets = tweets.sample(frac=1)\n","print(f'Número de tweets: {len(tweets)}\\n')\n","print(tweets.head())"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /home/lucas/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["nltk.download('stopwords')\n","pt_stop = set(nltk.corpus.stopwords.words('portuguese'))"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import re\n","from nltk.stem import WordNetLemmatizer\n","\n","stemmer = WordNetLemmatizer()\n","\n","def preprocess_text(document):\n","\n","        # removing urls\n","        document = re.sub(r'http\\S+', '', document)\n","\n","        # removing mentions\n","        document = re.sub(r'\\B@\\w+', '', document)\n","\n","        # remove all the special characters\n","        document = re.sub(r'\\W', ' ', str(document))\n","\n","        # remove all single characters\n","        document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n","\n","        # remove single characters from the start\n","        document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document)\n","\n","        # substituting multiple spaces with single space\n","        document = re.sub(r'\\s+', ' ', document, flags=re.I)\n","\n","        # removing prefixed 'b'\n","        document = re.sub(r'^b\\s+', '', document)\n","\n","        # converting to lowercase\n","        document = document.lower()\n","\n","        # lemmatization\n","        tokens = document.split()\n","        tokens = [stemmer.lemmatize(word) for word in tokens]\n","        tokens = [word for word in tokens if word not in pt_stop]\n","        tokens = [word for word in tokens if len(word) > 3]\n","\n","        return ' '.join(tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ZV-mwXjWVoLT"},"source":["# Modelagem de Tópicos"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"VJBsIdssWQC3"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package omw-1.4 to /home/lucas/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n","[nltk_data] Downloading package wordnet to /home/lucas/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","nltk.download('omw-1.4')\n","nltk.download('wordnet')"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Batches: 100%|██████████| 10/10 [00:05<00:00,  1.91it/s]\n","2022-08-25 18:07:05,908 - BERTopic - Transformed documents to Embeddings\n","2022-08-25 18:07:14,398 - BERTopic - Reduced dimensionality\n","2022-08-25 18:07:14,456 - BERTopic - Clustered reduced embeddings\n"]}],"source":["# create model \n","model = BERTopic(language=\"multilingual\", verbose=True, min_topic_size=3, top_n_words=10, calculate_probabilities=True)\n","\n","# convert to list \n","docs = tweets.text.to_list()\n","\n","# Pre-processamento\n","for i, doc in enumerate(docs):\n","    docs[i] = preprocess_text(doc)\n","\n","tweets_topic, probabilities = model.fit_transform(docs)"]},{"cell_type":"markdown","metadata":{},"source":["Adicionando o tópico de cada tweet no Dataframe"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>author_id</th>\n","      <th>conversation_id</th>\n","      <th>created_at</th>\n","      <th>text</th>\n","      <th>id</th>\n","      <th>candidato</th>\n","      <th>topico</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>102</th>\n","      <td>3.337476e+07</td>\n","      <td>1.560396e+18</td>\n","      <td>2022-08-18 22:41:15+00:00</td>\n","      <td>Pare pra pensar e me responda: se Bolsonaro ou...</td>\n","      <td>1.560396e+18</td>\n","      <td>ciro</td>\n","      <td>6_pequenos_custou_quanto_básico</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>2.670727e+09</td>\n","      <td>1.559313e+18</td>\n","      <td>2022-08-15 22:56:23+00:00</td>\n","      <td>Nós nordestinos, quando a gente se perde, a ge...</td>\n","      <td>1.559313e+18</td>\n","      <td>lula</td>\n","      <td>6_pequenos_custou_quanto_básico</td>\n","    </tr>\n","    <tr>\n","      <th>70</th>\n","      <td>2.670727e+09</td>\n","      <td>1.558948e+18</td>\n","      <td>2022-08-14 22:46:32+00:00</td>\n","      <td>Bolsonaro tenta se aproveitar do PIX, mas na r...</td>\n","      <td>1.558948e+18</td>\n","      <td>lula</td>\n","      <td>-1_brasil_campanha_quero_horas</td>\n","    </tr>\n","    <tr>\n","      <th>241</th>\n","      <td>1.283729e+08</td>\n","      <td>1.558492e+18</td>\n","      <td>2022-08-13 16:32:42+00:00</td>\n","      <td>- Agradeço aos mais de 450 mil espectadores qu...</td>\n","      <td>1.558492e+18</td>\n","      <td>bolsonaro</td>\n","      <td>6_pequenos_custou_quanto_básico</td>\n","    </tr>\n","    <tr>\n","      <th>256</th>\n","      <td>1.283729e+08</td>\n","      <td>1.557765e+18</td>\n","      <td>2022-08-11 16:32:40+00:00</td>\n","      <td>- A redução representa queda de R$ 0,22 por li...</td>\n","      <td>1.557767e+18</td>\n","      <td>bolsonaro</td>\n","      <td>0_ciro_vivo_lula_equipelula</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        author_id  conversation_id                created_at  \\\n","102  3.337476e+07     1.560396e+18 2022-08-18 22:41:15+00:00   \n","60   2.670727e+09     1.559313e+18 2022-08-15 22:56:23+00:00   \n","70   2.670727e+09     1.558948e+18 2022-08-14 22:46:32+00:00   \n","241  1.283729e+08     1.558492e+18 2022-08-13 16:32:42+00:00   \n","256  1.283729e+08     1.557765e+18 2022-08-11 16:32:40+00:00   \n","\n","                                                  text            id  \\\n","102  Pare pra pensar e me responda: se Bolsonaro ou...  1.560396e+18   \n","60   Nós nordestinos, quando a gente se perde, a ge...  1.559313e+18   \n","70   Bolsonaro tenta se aproveitar do PIX, mas na r...  1.558948e+18   \n","241  - Agradeço aos mais de 450 mil espectadores qu...  1.558492e+18   \n","256  - A redução representa queda de R$ 0,22 por li...  1.557767e+18   \n","\n","     candidato                           topico  \n","102       ciro  6_pequenos_custou_quanto_básico  \n","60        lula  6_pequenos_custou_quanto_básico  \n","70        lula   -1_brasil_campanha_quero_horas  \n","241  bolsonaro  6_pequenos_custou_quanto_básico  \n","256  bolsonaro      0_ciro_vivo_lula_equipelula  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["topic_names = model.generate_topic_labels(nr_words=4)\n","\n","# Array indicando o tópico de cada tweet (numérico -> índice do array \"topic_names\" + 1)\n","# print(tweets_topic)\n","# Array com todos os tópicos nomeados\n","# print(topic_names)\n","\n","for index, tweet_topic in enumerate(tweets_topic):\n","    tweets.at[index + 1, 'topico'] = topic_names[tweet_topic + 1]\n","\n","tweets.head()"]},{"cell_type":"markdown","metadata":{},"source":["Abaixo, os tópicos identificados entre todos os tweets"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["    Topic  Count                                               Name\n","0      -1     53                     -1_brasil_campanha_quero_horas\n","1       0     26                        0_ciro_vivo_lula_equipelula\n","2       1     25                       1_luladay_noite_gettr_baixar\n","3       2     21          2_melhor_brasildaesperança_esperança_pais\n","4       3     16                        3_deus_cristãos_crime_irmão\n","5       4     15                              4_2022_jair_aula_giro\n","6       5     15                5_famílias_safra_desemprego_milhões\n","7       6     13                    6_pequenos_custou_quanto_básico\n","8       7     13               7_redução_combustíveis_energia_preço\n","9       8     12                8_ciro_cironorodaviva_pergunta_rota\n","10      9     11                     9_carta_drogas_saudades_aborto\n","11     10      9                         10_eleição_voto_falar_café\n","12     11      8                11_política_corrupção_porque_errado\n","13     12      8                12_programa_renda_mínima_distribuir\n","14     13      8             13_estímulo_brasil_competições_decreto\n","15     14      7                      14_vamos_quer_guiar_merecemos\n","16     15      6                   15_juros_entregou_maior_pandemia\n","17     16      5               16_abraço_família_vivendo_prolonguem\n","18     17      5                17_garantido_governo_programa_renda\n","19     18      5               18_entenda_maconha_drogas_organizado\n","20     19      5              19_auxílio_emergencial_dezembro_agora\n","21     20      4                     20_campanha_viável_ficha_limpa\n","22     21      4  21_reconstruirmos_brasildaesperança_eleições_mina\n","23     22      3            22_oportunidade_guaianases_mesmas_tensa\n","24     23      3          23_empresas_precisamos_recuperar_empregos\n"]}],"source":["freq = model.get_topic_info()\n","print(freq)"]},{"cell_type":"markdown","metadata":{"id":"HooJDbp4WERL"},"source":["# Análise de Sentimentos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ANENPKpmWQeE"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"wYl-0IqqWI6u"},"source":["# Similaridade de Textos"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"5LANdfj4WRBM"},"outputs":[],"source":["def monta_docs_tweets(df, topico, coluna_alvo, candidatos):\n","    lista_tweets = []\n","    #df_topico = df[df['topico'] == topico]\n","    df_topico = df\n","\n","    for cand in candidatos:\n","        df_cand = df_topico[df_topico['candidato'] == cand]\n","        lista_tweets_cand = df_cand[coluna_alvo].to_list()\n","        lista_tweets.append(lista_tweets_cand)\n","    \n","    docs = np.concatenate(lista_tweets)\n","    return docs\n","\n","def monta_docs_concat_topico(df, topico, coluna_alvo, candidatos):\n","    docs = []\n","    df_topico = df[(df['topico'] == topico)]\n","    for cand in candidatos:\n","        df_topico_cand = df_topico[df_topico['candidato'] == cand]\n","        texto = ' '.join(df_topico_cand[coluna_alvo].to_list())\n","        docs.append(texto)\n","    return docs\n","\n","\n","def monta_docs_concat_candidato(df, coluna_alvo, candidatos):\n","    docs = []\n","    for cand in candidatos:\n","        df_cand = df[df['candidato'] == cand]\n","        texto = ' '.join(df_cand[coluna_alvo].to_list())\n","        docs.append(texto)\n","    return docs\n","\n","stop_words_ptbr = nltk.corpus.stopwords.words('portuguese')\n","\n","def normaliza_tweet(tweet):\n","    tweet = re.sub(r'[^a-zA-Z0-9\\s]', '', tweet, re.I|re.A)\n","    tweet = tweet.lower()\n","    tweet = tweet.strip()\n","    tokens = nltk.word_tokenize(tweet)\n","    tokens_filtrados = [token for token in tokens if token not in stop_words_ptbr]\n","    tweet_tokens = ' '.join(tokens_filtrados)\n","    return tweet_tokens\n","\n","def vetoriza_docs(lista_docs):\n","    corpus_vetorizado = np.vectorize(lista_docs)\n","    return corpus_vetorizado\n","\n","def gera_matriz_tfidf(corpus_vetorizado):\n","    tf = TfidfVectorizer(ngram_range=(1, 2), min_df=1)\n","    matriz_tfidf = tf.fit_transform(corpus_vetorizado)\n","    return matriz_tfidf\n","\n","def similaridade_pares(matriz_tfidf):\n","    dict_docs_sim = cosine_similarity(matriz_tfidf)\n","    df_sim = pd.DataFrame(dict_docs_sim)\n","    return df_sim\n","\n","def renomear_colunas(df, candidatos):\n","    df.columns = candidatos\n","    return df\n","\n","def calcula_similaridade_topico(df, topico, coluna_alvo, candidatos):\n","    lista_docs = monta_docs_concat_topico(df, topico, coluna_alvo, candidatos)\n","    normaliza_tweets = np.vectorize(normaliza_tweet)\n","    corpus_normalizado = normaliza_tweets(lista_docs)\n","    matriz_tfidf = gera_matriz_tfidf(corpus_normalizado)\n","    df_sim = similaridade_pares(matriz_tfidf)\n","    df_sim_cands = renomear_colunas(df_sim, candidatos)\n","\n","    return df_sim_cands\n","\n","def calcula_similaridade_candidatos(df, coluna_alvo, candidatos):\n","    lista_docs = monta_docs_concat_candidato(df, coluna_alvo, candidatos)\n","    normaliza_tweets = np.vectorize(normaliza_tweet)\n","    corpus_normalizado = normaliza_tweets(lista_docs)\n","    matriz_tfidf = gera_matriz_tfidf(corpus_normalizado)\n","    df_sim = similaridade_pares(matriz_tfidf)\n","    df_sim_cands = renomear_colunas(df_sim, candidatos)\n","\n","    return df_sim\n","\n","def calcula_similaridade_topicos(df, topicos, coluna_alvo, candidatos):\n","    dfs_sim = []\n","    for topico in topicos:\n","        dfs_sim.append(calcula_similaridade_topico(df, topico, coluna_alvo, candidatos))\n","        \n","    sim_dict = dict(zip(topicos, dfs_sim))\n","    return sim_dict\n","\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["['0_ciro_vivo_lula_equipelula',\n"," '1_luladay_noite_gettr_baixar',\n"," '2_melhor_brasildaesperança_esperança_pais']"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df_freq = model.get_topic_info()\n","topicos_mais_frequentes = df_freq['Name'].to_list()[1:4]\n","topicos_mais_frequentes"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Para tópico = 0_ciro_vivo_lula_equipelula\n","       lula  bolsonaro      ciro\n","0  1.000000   0.019666  0.030552\n","1  0.019666   1.000000  0.010793\n","2  0.030552   0.010793  1.000000\n","----------------------------------\n","Para tópico = 1_luladay_noite_gettr_baixar\n","       lula  bolsonaro      ciro\n","0  1.000000   0.026899  0.085612\n","1  0.026899   1.000000  0.027070\n","2  0.085612   0.027070  1.000000\n","----------------------------------\n","Para tópico = 2_melhor_brasildaesperança_esperança_pais\n","       lula  bolsonaro      ciro\n","0  1.000000   0.020207  0.053028\n","1  0.020207   1.000000  0.025134\n","2  0.053028   0.025134  1.000000\n","----------------------------------\n"]}],"source":["candidatos = [\"lula\", \"bolsonaro\", \"ciro\"]\n","analise_similaridade = calcula_similaridade_topicos(tweets, topicos_mais_frequentes, \"text\", candidatos)\n","for topico in analise_similaridade.keys():\n","    print(f\"Para tópico = {topico}\")\n","    print(analise_similaridade[topico])\n","    print('----------------------------------')"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>lula</th>\n","      <th>bolsonaro</th>\n","      <th>ciro</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.000000</td>\n","      <td>0.336546</td>\n","      <td>0.370636</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.336546</td>\n","      <td>1.000000</td>\n","      <td>0.307959</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.370636</td>\n","      <td>0.307959</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       lula  bolsonaro      ciro\n","0  1.000000   0.336546  0.370636\n","1  0.336546   1.000000  0.307959\n","2  0.370636   0.307959  1.000000"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["analise_sim_cand = calcula_similaridade_candidatos(tweets, \"text\", candidatos)\n","analise_sim_cand"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Projeto2-PLN.ipynb","provenance":[]},"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"},"kernelspec":{"display_name":"Python 3.9.5 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"}},"nbformat":4,"nbformat_minor":0}
